\chapter{Related Work}
\label{chapter:related_work}
\thispagestyle{myheadings}

% set this to the location of the figures for this chapter. it may
% also want to be ../Figures/2_Body/ or something. make sure that
% it has a trailing directory separator (i.e., '/')!
\graphicspath{{2_Body/Figures/}}

\section{Introduction, Query optimization}
A database can be thought of as a list of tables, where in each table itself can be considered as a list of data points ordered initially in the sequence they are entered.
\par There are various tools which can be used to connect to a database, here we focus on structured query languages(SQL). A simple SQL query looks like this
\begin{lstlisting}[language=SQL]
    SELECT column_name_1, column_name_2
    FROM table_name
    WHERE condition
\end{lstlisting}
This query is essentially asking to display the 2 columns from the table where the condition given is satisfied. This to particular query might be looking simple, but if the condition introduced is a complex one or if the table from which we need to return the output is complex, the question of how to execute the query optimally becomes difficult to answer.

\section{Converting SQL queries to parse trees}
We don't describe the exact grammar for the convertion to the parse tree. In these parse trees, there are 2 types of nodes, one the atoms, which are essentially keywords in SQL, operators, constants and attributes. The second is Syntactic categories, these are names for families of subqueries in triangular brackets. Each of the syntactic category has unique expansion into atoms and further syntactic categories.
\section{Relational algebra}
As we saw above, order of operations matters, if the order of operations is not thoughtout and done blindly alot of redundant steps are executed and memory is moved around unnecessarily. There are few ways to atleast look and analyse the operations and how they can be simplied.
\par Let \textsc{R,S} be relations. Some simple laws, associativity and commutativity can easily be verified:-
\begin{itemize}
    \item $R\times S = S \times R$
    \item $(R\times S) \times T = R\times (S \times T)$
    \item $R \bowtie S = S \bowtie R$
    \item $(R \bowtie S) \bowtie T = R \bowtie (S \bowtie T)$
    \item $R \cup S = S \cup R$
    \item $(R \cup S) \cup T = R \cup (S \cup T)$
    \item $R \cap S = S \cap R$
    \item $(R \cap S) \cap T = R \cap (S \cap T)$
\end{itemize}
When applying associative law on relations, need to be careful whether the conditions actually makes sense after the order is changed.
\par While the above identities work on both sets and bags(bags allow for repeatition). To show that laws for sets and bags do differ an easy way is to consider the distributive property.\\
$A\cap _S(B\cup_S C) = (A\cap_S B)\cup_S(A\cap_S C) $\\
$A\cap _B(B\cup_B C) \neq (A\cap_B B)\cup_B(A\cap_B C)$\\
We can simply show it with an example. Let $A=\{t\},B=\{t\},C=\{t\}$. The LHS comes to be $\{t\}$, whereas RHS is $\{t,t\}$
\subsection{Select operator $\sigma$}
First we start with simple properties of the $\sigma$ operator.
\begin{itemize}
    \item $\sigma_{C_1} \land \sigma_{C_2}(R) = \sigma_{C_1}(\sigma_{C_2}(R)) $
    \item $\sigma_{C_1} \lor \sigma_{C_2}(R) = (\sigma_{C_1}(R))\cup_S(\sigma_{C_2}(R))$
\end{itemize}
\section{Converting Parse trees into logical expression}
\section{Explain difficulties/ Time complexity}
\section{Optimzation using relation algebra}
\section{Introduction to Data Streams}
\section{Data stream windowing}
\section{Query Processing of data streams(Combine the DBMS and DSMS)}
\section{Challenges of query optimization on data streams}
\section{Conclusion and discussion}


\section{SQL Query compiler}
\label{sec:sql}
The steps involved are
\subsection{Parsing}
In a very general sense, given an SQL query, SQL converts it into a parse tree based on SQL grammar.
\subsection{Preprocessing}
This step has several functions.
\par If a "view" is used in the query as a relation, then each instance has to be replaced by the parse tree.
\par The preprocessor also has to conduct semantic checking, that is, check if relations used exist, check for ambiguity, and type checking.
If a parse tree passes the preprocessing then it is said to be \textbf{valid}
\subsection{Logical Query Plan}
The first step is to modify the parse tree into using operators and operators of relational algebra.
\par The next step is to convert expression obtained from the above substitution and modify it into an expression which can be converted to most efficient physical query plan.
\par To improve the algebraic expression obtained, few common steps taken are pushing down selections and projections carefully, carefully placing duplicate eliminations, combining selections, showing associativity and commutivity in the expression to help with enumeration.
\par At the end when we have the expression ready, we enumerate the physical plans and calculate their cost of execution and select the method with the lowest cost.
\subsection{Cost Estimation}
We need to consider what algorithm each operator in the expression is going to use, such as join, sort, scanning and more. Also need to consider the order for the associative and commutative operators, because at the end the operators are binary and how the output of one operator is provided as an input to the next/ outter operator in the expression. 
\section{System R}
\label{sec:systemR}
\section{Deep Reinforcement learning}
\label{sec:drl}

Markov decision process(MDP) is used to formalize various types of stochastic processes. In MDPs, the goal of the agent is to make a sequence of actions to optimize/ maximize an objective function. \\
Formally a MDP is a $5-$tuple 
\begin{center}
$\langle S,A,P(s,a),R(s,a), s_0 \rangle $\\
$S \to $ Set of all possible states the agent can be in.\\
$A \to $ Set of all possible actions the agent can take.\\
$P(s,a) \to $ A probability distribution of going to various states given current state and action. $s^{1} \sim P(s,a)$\\
$R(s,a) \to $ Reward for taking action $a$ on state $s$.\\
$s_0 \to $ Describes the initial state of the system/ agent.
\end{center}
The performance of the agent is measured using the rewards collected along the way through various states. So the objective of an MDP is to find a policy $\pi:S\rightarrow A$, a function that maps states to actions, in order to maximize the expected value:-
\begin{center}
    \[ 
    \argmax_{\pi} \mathbb{E} \left[ \sum^{T-1}_{t=0}R(s_{t},a_{t})  \right]
    \] 
    subject to $s_{t+1} = P(s_{t},a_{t}), a_{t} = \pi{s_{t}}$
\end{center}
This method does not reduce the search space, and unlikely greedy solution, this will lead to an optimal solution. This method does not reduce the search space, and unlikely greedy solution, this will lead to an optimal solution.
\par Reinforcement learning(RL) is a technique which optimizes MDPs iteratively, by running a simulation in each iteration and changing the policy to find an optimal one based on the cumulative reward.
\section{Relations}
\label{sec:relations}
A common method/ data structure used to formalize joins
\par \textbf{Query Graph $\to$} A query graph $G$ is an undirected graph, where each relation R is a vertex and each join predicate $\rho$ defines an edge between $2$ vertices. Let $\kappa_G$ denote the number of connected components in $G$
\par A join of relation $R_1, R_2$, in the graph corresponds to remove the vertices $v_{R_1}, v_{R_2}$, replacing them with a vertex $v_{R_1+R_2}$, the edges of the form $(v_{R_1},v) \& (v_{R_2},v)$ are replaced by $(v_{R_1+R_2}, v)$. Note each reduction reduces number of vertices by one, so this process is repeated until there are $\kappa_G$ number of vertices left.
\par \textbf{Join Optimization Problem $\to$} Let $G$ be a query graph and $J$ be a join cost model. Find sequence, $c_1\circ c_2\circ ... \circ c_n$ resulting in $|V| = \kappa_G$ to minimize
\begin{center}
    \[
        \min_{c_1,c_2,...c_n} \sum^{n}_{i=1}J(c_i)
    \] 
    subject to $G_{i+1} = c(G_i)$
\end{center}
Using these definitions, we define a MDP. 
\begin{center}
$\langle \{G_0,G_1,...G_T\},c,P(G,c),-J, G \rangle $\\
\end{center}
We are still not certain about how the cost function $J$ is structured. We are still not certain about how the cost function $J$ is structured. We are still not certain about how the cost function $J$ is structured.

We are still not certain about how the cost function $J$ is structured.









