\chapter{Stream Optimization}
\label{chapter:stream_optimization}
\thispagestyle{myheadings}

% set this to the location of the figures for this chapter. it may
% also want to be ../Figures/2_Body/ or something. make sure that
% it has a trailing directory separator (i.e., '/')!
\graphicspath{}

\section{Introduction}
 A stream is an ordered sequence of data items, which are values that can range from simple numbers to flat tuples to more  elaborate structured data that may be deeply nested and have variable size. Streams are conceptually infinite, in the sense that  as the streaming computation unfolds over time, the sequence of data items is unbounded in length\cite{stream_query_optimization}.
\par Stream query optimization is the process of modifying a stream processing query, often by changing its graph topology and/or  operators, with the aim of achieving better performance (such as higher throughput, lower latency, or reduced resource usage), while preserving the semantics of the original query.
\par An optimization should be both safe and profitable. An optimization is safe if it can be applied to a stream query without   changing what it computes, as determined by the userâ€™s requirements. An optimization is profitable if it makes the stream query  faster, as measured by metrics that matter to the user, such as throughput, latency, or resource efficiency. There is a  substantial literature on different stream query optimizations, with different safety and profitability characteristics. This  entry lists the most common optimizations along with short descriptions.
\par Possible areas of optimization are, batch size, operation combining/ dividing, memory assignment, message passing, operation reordering, garbage collection. We focus mostly on operation reordering.
\par Last chapter showcased how Deep reinforcement learning can help solve problems by telling the best course of action. We are going to use this technique to improve our operation reordering.

\section{Formalization Requirements}
To even being to tackle the problem first we need to define the problem formally to be able to analyze it.\\
For the experiment to be reconstructible to the closest possible degree and to define a concrete problem statement for reinforcement learning, we will need to decide upon the following at least:-
\begin{itemize}
    \item Data Soucre generator
    \item Query to execute
    \item The underlying algorithms have to be fixed
    \item Featurization method of DRL
    \item How will DRL change over time
    \item Output of DRL
    \item Evaluation
\end{itemize}
Before going on the give answers to the above, we also need to justify using this(DRL) technique.

\section{Problem Statement}
As discussed in the previous chapter, given a query there are multiple ways of executing the query to return the result, these ways correspond to a query plan and for each query plan there is a cost associated to it, one component of the costs is the time required for execution.\\
We can represent the plans by $P_{i}$ and the time corresponding to the plan as $C_{i}$. So we can represent them as $\{(P_{i},C_{i})\}_{i=1}^{n}$. Our goal is to find query plan $P_{i}$ with the minimum $C_{i}$.

\section{Approach}
Currently we make the following assumptions:-
\begin{itemize}
    \item We have our data source generator with say a fixed seed, which will ensure we have a constant source of data.
    \item The query to execute is given, that is the window size for data streams is given.
    \item The query has combination of data streams and static relations as well as operators such as selection, projections, groupby and more.
\end{itemize}
As mentioned eariler, we are going to focus on finding an order of operations to execute to reduce/ minimize the query execution time.

% Can assume there is only 1 stream, it contains all the attributes.
% Specific example and show its execution. show a simple and a complex query, show it's execution plans.
% A smaller problem definition, then tell the approach.
% Attribute(ordering, algorithms, operators) for plan execution and properties(entropy, speed, throughput) for the data streams. overall execution time of plan depends on both attribute of plan and properties of data stream.
% continuous queries not historical.

\par Say there is a data streams $S$ with $m$ attributes and relations $R_1,R_2,...,R_{n}$ each with $m_{i}$ attributes.
\\ That is to say there are total of $(m + \sum_{i=1}^{n}m_i)=g$ attributes. We can use $1-0$ encoding so that any attribute or a combination in this schema can be represented by an array/vector $v$ of length $g$. 

\[ 
   v_i=
   \begin{cases} 
      1 & if, i \in combination \\
      0 & otherwise 
   \end{cases}
\] 
This vector will help represent attributes listed in the query. We can further replace $1$ with the entropy of the attribute.
\par For our Deep reinforcement learning data we will need the rewards, actions, current and next possible state, we will need to encode these in a $4-$tuple, $(F_c,F_n,$ Action, Reward $)$. When we have enough of these examples we are use them to train our model and try to get a better ordering.

\section{Example}
We look at linear road benchmark to test our hypothesis.\
\subsection{Input}
\textbf{CarLocStr}: Stream of car location reports. This forms primary input to the system. 
\begin{lstlisting}[language=SQL]
    CarLocStr(car_id,        /* unique car identifier       */
              speed,         /* speed of the car            */
              exp_way,       /* expressway: 0..10           */
              lane,          /* lane: 0,1,2,3               */ 
              dir,           /* direction: 0(east), 1(west) */
              x-pos);        /* coordinate in express way   */
\end{lstlisting}
\textbf{AccBalQueryStr}: Stream of account-balance adhoc queries. Each query requests the current account balance of a car. 
\begin{lstlisting}[language=SQL]
    AccBalQueryStr(car_id,   
                   query_id);/* id used to associate 
                              * responses with queries      */
\end{lstlisting}
\textbf{ExpQueryStr}: Stream of adhoc queries requesting the expenditure of a car for the current day. 
\begin{lstlisting}[language=SQL]
    ExpQueryStr(car_id,
                query_id);
\end{lstlisting}
\textbf{TravelTimeQueryStr}: Stream of expected-travel-time adhoc queries. 
\begin{lstlisting}[language=SQL]
    TravelTimeQueryStr(query_id,
                       exp_way,
                       init_seg,      /* initial segment */
                       fin_seg,       /* final segment   */
                       time_of_day,   
                       day_of_week);
\end{lstlisting}
\textbf{CreditStr}: The stream of credits to the account corresponding to a car. 
\begin{lstlisting}[language=SQL]                   
    CreditStream(car_id, credit);
\end{lstlisting}
Instead of assuming multiple streams for input we will combine them and assuming a single data stream as input.

\subsection{Query}
In this section we showcase the query statement for a simple and a complex query, convert it into a SQL query and show the complexity within. We use the query statement from linear road itself.
\begin{itemize}
    \item \textbf{Query 1, Segment Average Speed } : The average speed of a particular car in a segment over the last 5 minutes. 
    \item \textbf{Query 2, Toll Computation for Segments} : The toll for each segment depends on the average speed and volume of the cars in the segment, and on the presence of accidents in downstream segments. 
\end{itemize}
Now to convert the query statement to actual syntax/ query and showcase few different query plans and how the cost might change.

\subsection{Segment Average Speed}
First we convert the simpler query.
\begin{lstlisting}[language=SQL]
    SELECT exp_way, dir, seg, AVG(speed) as speed,
    FROM CarSegStr [RANGE 5 MINUTES]
    WHERE car_id = target
    GROUP BY exp_way, dir, seg;
\end{lstlisting}
To convert this into a query plan, as seen in the previous chapter, we use relational algebra to convert into a query plan.
$$\gamma_{\text{exp\_way,dir,seg, AVG(speed)}}(\sigma_{\text{car\_id = target}}(\text{CarSegStr}))$$
Of course, the above mentioned method/ bracketing is one way of executing the query. A small modification from the rules in previous chapter can lead to the following improvement!
$$\gamma_{\text{exp\_way,dir,seg, AVG(speed)}}(\pi_{\text{exp\_way,dir,seg, speed}}(\sigma_{\text{car\_id = target}} (\text{CarSegStr})))$$
Now here we are assuming that $CarSegStr$ is a single stream, ready to be used, incase it was a more complicated, that is, it was obtained by joining 2 different streams/ relations with a condition $C$ a further improvement is possible!\\
$$\gamma_{\text{exp\_way,dir,seg, AVG(speed)}}(\pi_{\text{exp\_way,dir,seg, speed}}(\sigma_{\text{car\_id = target}} (S_1\underset{C \land (\text{car\_id = target})}{\bowtie}S_2)))$$
Of course further improvements can be made, but that will require us to look into attributes of the two streams $S_1$ and $S_2$
\par So to conclude, we made an improvement from the naive plan to a much more efficient plan
\begin{itemize}
    \item $\gamma_{\text{exp\_way,dir,seg, AVG(speed)}}(\sigma_{\text{car\_id = target}}(\text{CarSegStr}))$
    \item $\gamma_{\text{exp\_way,dir,seg, AVG(speed)}}(\pi_{\text{exp\_way,dir,seg, speed}}(\sigma_{\text{car\_id = target}} (\text{CarSegStr})))$
    \item $\gamma_{\text{exp\_way,dir,seg, AVG(speed)}}(\pi_{\text{exp\_way,dir,seg, speed}}(\sigma_{\text{car\_id = target}} (S_1\underset{C \land (\text{car\_id = target})}{\bowtie}S_2)))$
\end{itemize}

\subsection{Toll Computation for Segments}
Now to convert tackle the more complex query, \textbf{Query 2, }\\
Before going to that, note the steps to perform a query on streams requires to first generate a relation from stream, make relations from this derived relation and then output a stream from the derived relation. This is a 3 step process. \\
Now we look at the more complex query.
\par \textbf{SegAvgSpeed}: The average speed of the cars in a segment over the last 5 minutes. 

\begin{lstlisting}[language=SQL]
SELECT exp_way, dir, seg, AVG(speed) as speed,
FROM CarSegStr [RANGE 5 MINUTES]
GROUP BY exp_way, dir, seg;
\end{lstlisting}


\par \textbf{SegVol}: Relation containing the number of cars currently in a segment. The relation CurCarSeg is used to determine the cars in each segment.

\begin{lstlisting}[language=SQL]
SELECT exp_way, dir, seg, COUNT(*) as volume
FROM CurCarSeg
GROUP BY exp_way, dir, seg;
\end{lstlisting}


\par \textbf{SegToll}:The toll for each segment. There are no entries in the relation for segments having no toll. A segment is tolled only if the average speed of the segment is less than $40$, and if it is not affected by an accident. If a segment is tolled, its toll is basetoll $* (\#$cars $- 150) * (\#$cars $- 150)$. We modify this query to remove the not affected by accident  condition.


\begin{lstlisting}[language=SQL]
SELECT S.exp_way, S.dir, S.seg, basetoll*(V.volume-150)*(V.volume-150)
FROM SegAvgSpeed as S, SegVol as V
WHERE S.exp_way = V.exp_way and S.dir = V.dir and S.seg = V.seg
      and S.speed <= 40;
\end{lstlisting}

These 3 steps combined give us the desired query.
Where $S$ in turn calculated via this process
$$\pi_{\text{exp\_way, dir, seg, speed}}(\gamma_{\text{exp\_way,dir,seg}} (\text{CarSegStr}))$$
Where $S$ in turn calculated via this process
$$\pi_{\text{exp\_way, dir, seg, columm}}(\gamma_{\text{exp\_way,dir,seg}} (\text{CurCarSeg}))$$

Finally combining the two with the $3^{rd}$ query 
$$\pi_{\text{S.exp\_way, S.dir, S.seg, S.toll}}$$
$$\sigma_{(\text{S.exp\_way = V.exp\_way}) \land (\text{S.dir = V.dir}) \land (\text{S.seg = V.seg})\land (\text{S.speed} \leq 40)}(\text{S,V})$$
We can push down the projection and then break down the selection condition, for ease of notation, substitute the 4 conditions as $C_1,C_2,C_3,C_4$ respectively.
$$\pi_{\text{S.exp\_way, S.dir, S.seg, S.toll}}(\sigma_{C_1}(\sigma_{C_2}(\sigma_{C_3}(\sigma_{C_4}(\text{S,V})))))$$
Now we can list few different query plans
$$\pi_{\text{S.exp\_way, S.dir, S.seg, S.toll}}(\sigma_{C_1}(\sigma_{C_2}(\sigma_{C_3}(\sigma_{C_4}(\text{S,V})))))$$
$$\pi_{\text{S.exp\_way, S.dir, S.seg, S.toll}}(\sigma_{C_1}(\sigma_{C_2}(\sigma_{C_4}(\sigma_{C_3}(\text{S,V})))))$$
$$\pi_{\text{S.exp\_way, S.dir, S.seg, S.toll}}(\sigma_{C_1}(\sigma_{C_3}(\sigma_{C_2}(\sigma_{C_4}(\text{S,V})))))$$

The goal is to try to figure out the best possible method of rearranging these associative operations, in this thesis we try out using deep reinforcement learning to try to predict the best possible move.

\begin{comment}

$$(\text{E.exp\_way=A.exp\_way}\land \text{E.dir=East}\land \text{A.dir=EAST}\land \text{E.seg<A.seg} \land \text{E.seg>A.seg-5})}$$




\section{Optimization Specifications}
A first attempt at making a DQN we might narrow down to the fact that DQN will be query specific, we do not know the exact state we will be in nor do we know the exact reward we get until we do the action. 
\par The interesting part of this problem only arises due to complex queries, hence we need to remember that when choosing a query to solve, operations like join, Aggregation, duplication elemination and more result in complex queries generally.
\par Window size kept for training can change and a good window size needs to be figured out.
\par The underlying algorithms for joins, memory access and message passing should be fixed so results aren't affected by multiple attributes.
\par Need to encode the query and convert it into features for the DQN.
\par To determine what all should the features should capture, we need to look at the operations we will be performing, we also need an encoding for the query itself as well as the notations used in the previous chapter to calculate complexity.
\begin{itemize}
\item $B(R) \coloneqq$ is the number of blocks needed to hold all the tuples of relation $R$.
\item $T(R) \coloneqq$ is the number of tuples of relation $R$.
\item $V(R,a) \coloneqq$ is the value count for attribute a of relation $R$, that is, the number of distinct values relation $R$ has in attribute $a$.
\item $V(R, [ a_1 , a_2,..., a_n]) \coloneqq$ is the number of distinct values $R$ has when all of attributes $a_1, a_2,..., a_n$ are considered together, that is, the number of tuples in $\delta(\pi_{a_1,a_2,...,a_n}(R))$
\end{itemize}

\par The DQN should tell according to it's estimates what is the best action to take, what is the best ordering, which operation to perform.
\end{comment}


% 1. What is the stream query optimization? 
% We can have complex queries. Conctinous queries because it runs on top of the data stream. 
% They include join, selection, projection, user-defined functions, etc. 
% 
% 2. If we machine learning what is for us the training data. 
% We need to know about history of different runs of queries. 
% Query-1 can have different execution plans. {(P1, Cost1), (P2, Cost2), ... (Pn, Const_n)}. There is a min cost. 
% Our query does not match one-to-one to the past queries. How we can use parts of the past? 
% Query-1 comes with features of {f1, f2, ..., fn}, we have an optimized plan for this query. Things like graphs structures. 
% Query-future , you can extract features from it {f1, f2, ..., fn}

% Problem is almost a similarity matching problem. 


% 3. What are my inputs to the Machine learning Algorithms? What are my labesl? Are these coinous or labels (1/0), multi-lables. 

% Assumptions: Can stream change over time? Can the Sliding window change? 
% Why you can not do exact similarity match? Because we have never run that query before. 
% Why I can not do simple kNN? 


